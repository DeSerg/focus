{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "MODULE_FULL_PATH = '/home/spopov/focus/pfe'\n",
    "sys.path.insert(1, MODULE_FULL_PATH)\n",
    "sys.path.append('.')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from network import Network\n",
    "from utils import utils\n",
    "from utils.dataset import Dataset\n",
    "from utils.imageprocessing import preprocess\n",
    "\n",
    "\n",
    "from retinaface import RetinaFace\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import align.crop_ijba as crop\n",
    "import align.align_dataset as align\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "PFE_PATH='/home/spopov/focus/pfe'\n",
    "DATASET_PATH = os.path.join(PFE_PATH, '/home/spopov/datadrive/IJB/IJB-B/')\n",
    "HINTS_FILEPATH = os.path.join(DATASET_PATH, 'protocol/cluster/test8/ijbb_detection_clustering_hint_100000.csv')\n",
    "IMAGES_PATH = os.path.join(DATASET_PATH, 'images/')\n",
    "FACES_PATH = os.path.join(PFE_PATH, 'data/cluster/')\n",
    "\n",
    "EVAL_SCRIPT_PATH = os.path.join(DATASET_PATH, 'cluster_eval/association_modified_bcubed.py')\n",
    "GROUND_TRUTH_FILEPATH = os.path.join(DATASET_PATH, 'protocol/cluster/test8/ijbb_detection_clustering_ground_truth.csv')\n",
    "\n",
    "TEMPLATES_FILEPATH = os.path.join(PFE_PATH, 'templates.csv')\n",
    "CLUSTERS_FILEPATH = os.path.join(PFE_PATH, 'clusters.csv')\n",
    "\n",
    "IMAGE_SIZE = [96, 112]\n",
    "\n",
    "class Template:\n",
    "    def __init__(self, template_id, filename, img, box):\n",
    "        self.template_id = template_id\n",
    "        self.filename = filename\n",
    "        self.img = img\n",
    "        self.box = box\n",
    "        \n",
    "        self.cluster_index = None\n",
    "        self.confidence = None\n",
    "        self.features = None\n",
    "        \n",
    "    def draw(self):\n",
    "        if self.img is None:\n",
    "            return\n",
    "        \n",
    "        imgg = self.img / np.max(self.img) # normalize the data to 0 - 1\n",
    "        imgg = 255 * imgg # Now scale by 255\n",
    "        imgg = imgg.astype(np.uint8)\n",
    "        align_rgb = cv2.cvtColor(imgg, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(align_rgb)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames/10003.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hints_filenames = pd.read_csv(HINTS_FILEPATH)\n",
    "print(hints_filenames.iloc[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 16, 8] {'32': {'SCALES': (32, 16), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '16': {'SCALES': (8, 4), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '8': {'SCALES': (2, 1), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}}\n",
      "means [0. 0. 0.]\n",
      "use_landmarks True\n",
      "cascade 0\n",
      "sym size: 9\n",
      "Metagraph file: /home/spopov/focus/pfe/log/sphere64_casia_am_PFE/20200515-123838/graph.meta\n",
      "Checkpoint file: /home/spopov/focus/pfe/log/sphere64_casia_am_PFE/20200515-123838/ckpt-3000\n",
      "INFO:tensorflow:Restoring parameters from /home/spopov/focus/pfe/log/sphere64_casia_am_PFE/20200515-123838/ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/spopov/focus/pfe/log/sphere64_casia_am_PFE/20200515-123838/ckpt-3000\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "detector = RetinaFace(os.path.join(PFE_PATH, 'model/R50'), 0, gpuid, 'net3')\n",
    "\n",
    "network = Network()\n",
    "network.load_model('/home/spopov/focus/pfe/log/sphere64_casia_am_PFE/20200515-123838')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "        self.template_id = template_id\n",
    "        self.filename = filename\n",
    "        self.img = img\n",
    "        self.box = box\n",
    "        \n",
    "        self.cluster_index = None\n",
    "        self.confidence = None\n",
    "        self.features = None\n",
    "        self.template_id = template_id\n",
    "        self.filename = filename\n",
    "        self.img = img\n",
    "        self.box = box\n",
    "        \n",
    "        self.cluster_index = None\n",
    "        self.confidence = None\n",
    "        self.features = None\n",
    "\n",
    "\n",
    "templates_dict = {}\n",
    "for template in templates:\n",
    "\n",
    "        \n",
    "        \n",
    "def template_dict(template):\n",
    "    d = {'template_id': template.template_id,\n",
    "        'filename': template.filename,\n",
    "        'img': template.img,\n",
    "        'box': template.box,\n",
    "#         'box_x': template.box[0],\n",
    "#         'box_y': template.box[1],\n",
    "#         'box_w': template.box[2],\n",
    "#         'box_h': template.box[3],\n",
    "        'landmarks': template.landmarks}\n",
    "    \n",
    "    \n",
    "def template_load(d):\n",
    "    t = Template(d[''])\n",
    "    \n",
    "def templates_load(df):\n",
    "    template_dicts = df.to_dict(orient='records')\n",
    "    templates = [template_load(template_dict) for template_dict in template_dicts]\n",
    "    return templates\n",
    "\n",
    "def build_templates(num=None, show_images=False):\n",
    "    templates = []\n",
    "    \n",
    "    templates_df = pd.Dataframe()\n",
    "    \n",
    "    if num is None:\n",
    "        num = hints_filenames.shape[0]\n",
    "        \n",
    "    for filename_i, filename in enumerate(hints_filenames['FILENAME'][:num], 1):\n",
    "        image_path = os.path.join(IMAGES_PATH, filename)\n",
    "        img = cv2.imread(image_path, flags=1)\n",
    "        if filename_i % 200 == 0:\n",
    "            print('\\r{} of {} images scanned for faces'.format(filename_i, num))\n",
    "        if img is None or img.ndim == 0:\n",
    "            print('Invalid image: %s' % impath)\n",
    "            count_fail += 1\n",
    "            continue\n",
    "\n",
    "        faces, landmarks = detector.detect(img)\n",
    "\n",
    "        if faces is None:\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        for face_i in range(faces.shape[0]):\n",
    "            box = faces[face_i].astype(np.int)\n",
    "\n",
    "    #         cv2.rectangle(rgb, (box[0], box[1]), (box[2], box[3]), (255,0,0), 2)\n",
    "    #         print(box)\n",
    "\n",
    "            bbox = (box[0], box[1], box[2] - box[0], box[3] - box[1])\n",
    "    #         print(bbox)\n",
    "    #         if crop.square_crop:\n",
    "    #             bbox = crop.square_bbox(bbox)\n",
    "    #         bbox = crop.pad_bbox(bbox, crop.padding_ratio)\n",
    "    #         print(img.dtype)\n",
    "\n",
    "    #         crop_img = crop.crop(img, bbox)\n",
    "    #         print(crop_img.shape)\n",
    "    #         print(crop_img.dtype)\n",
    "\n",
    "    #         imgg = crop_img / np.max(crop_img) # normalize the data to 0 - 1\n",
    "    #         imgg = 255 * imgg # Now scale by 255\n",
    "    #         imgg = imgg.astype(np.uint8)\n",
    "    #         crop_rgb = cv2.cvtColor(imgg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(crop_rgb)\n",
    "\n",
    "            face_landmarks = landmarks[face_i]\n",
    "            src_pts = [[face_landmarks[j][0], face_landmarks[j][1]] for j in range(5)]\n",
    "    #         print('src_pts: \\n', src_pts)\n",
    "            align_img, _, _ = align.align(img, src_pts, align.ref_pts, IMAGE_SIZE)\n",
    "        \n",
    "            impath_new = os.path.join(FACES_PATH, '{}_{}.jpg'.format(template_id, face_i))\n",
    "            cv2.imwrite(impath_new, align_img)\n",
    "#             imgg = align_img / np.max(align_img) # normalize the data to 0 - 1\n",
    "#             imgg = 255 * imgg # Now scale by 255\n",
    "#             imgg = imgg.astype(np.uint8)\n",
    "#             align_rgb = cv2.cvtColor(imgg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(align_rgb)\n",
    "            \n",
    "\n",
    "            template = Template(filename_i, filename, impath_new, bbox)\n",
    "            \n",
    "            templates_df.append(template_dict(template))\n",
    "            templates_df.to_csv(CLUSTERS_FILEPATH, mode='a', header=False, index=False)\n",
    "            \n",
    "\n",
    "        if show_images:\n",
    "            plt.figure()\n",
    "            plt.imshow(rgb)\n",
    "            plt.show()\n",
    "            \n",
    "    return templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def force_compare(compare_func, verbose=False):\n",
    "    def compare(t1, t2):\n",
    "        score_vec = np.zeros(len(t1))\n",
    "        for i in range(len(t1)):\n",
    "            if t1[i] is None or t2[i] is None:\n",
    "                score_vec[i] = 0\n",
    "            else:\n",
    "                score_vec[i] = compare_func(t1[i][None], t2[i][None])\n",
    "            if verbose and i % 1000 == 0:\n",
    "                sys.stdout.write('Matching pair {}/{}...\\t\\r'.format(i, len(t1)))\n",
    "        if verbose:\n",
    "            print('')\n",
    "        return score_vec\n",
    "    return compare\n",
    "\n",
    "def pair_MLS_score(x1, x2, sigma_sq1=None, sigma_sq2=None):\n",
    "    if sigma_sq1 is None:\n",
    "        x1, x2 = np.array(x1), np.array(x2)\n",
    "        assert sigma_sq2 is None, 'either pass in concated features, or mu, sigma_sq for both!'\n",
    "        D = int(x1.shape[1] / 2)\n",
    "        mu1, sigma_sq1 = x1[:,:D], x1[:,D:]\n",
    "        mu2, sigma_sq2 = x2[:,:D], x2[:,D:]\n",
    "    else:\n",
    "        x1, x2 = np.array(x1), np.array(x2)\n",
    "        sigma_sq1, sigma_sq2 = np.array(sigma_sq1), np.array(sigma_sq2)\n",
    "        mu1, mu2 = x1, x2\n",
    "    sigma_sq_mutual = sigma_sq1 + sigma_sq2\n",
    "    dist = np.sum(np.square(mu1 - mu2) / sigma_sq_mutual + np.log(sigma_sq_mutual), axis=1)\n",
    "\n",
    "    r = random.randint(0, 10)\n",
    "    if r % 7 == 0:\n",
    "#         print('pair_MLS_score: ', type(-dist[0]), -dist[0])\n",
    "        pass\n",
    "\n",
    "    return -dist[0]\n",
    "\n",
    "\n",
    "fc = force_compare(pair_MLS_score)\n",
    "\n",
    "def compare(x, y):\n",
    "     return fc([x], [y])[0]\n",
    "\n",
    "def max_similarity(features):\n",
    "    max_sim = 0\n",
    "    for i in range(len(features)):\n",
    "        for j in range(len(features)):\n",
    "            sim = compare(features[i], features[j])\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "    return max_sim\n",
    "                \n",
    "def distance(x, y, max_sim):\n",
    "    return 1 - compare(x, y) / max_sim\n",
    "\n",
    "def confidence_sigma(sigma_sq):\n",
    "    return -np.sum(np.log(sigma_sq), axis=0)\n",
    "\n",
    "def confidence(x):\n",
    "    x = np.array(x)\n",
    "    D = int(x.shape[0] / 2)\n",
    "    sigma_sq = x[D:]\n",
    "    return confidence_sigma(sigma_sq)\n",
    "\n",
    "\n",
    "def distance_func(x, y):\n",
    "    d = distance(x, y, MAX_SIMILARITY)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 of 66779 images scanned for faces\n",
      "400 of 66779 images scanned for faces\n",
      "600 of 66779 images scanned for faces\n",
      "800 of 66779 images scanned for faces\n",
      "1000 of 66779 images scanned for faces\n",
      "1200 of 66779 images scanned for faces\n",
      "1400 of 66779 images scanned for faces\n",
      "1600 of 66779 images scanned for faces\n",
      "1800 of 66779 images scanned for faces\n",
      "2000 of 66779 images scanned for faces\n",
      "2200 of 66779 images scanned for faces\n",
      "2400 of 66779 images scanned for faces\n",
      "2600 of 66779 images scanned for faces\n",
      "2800 of 66779 images scanned for faces\n",
      "3000 of 66779 images scanned for faces\n",
      "3200 of 66779 images scanned for faces\n",
      "3400 of 66779 images scanned for faces\n",
      "3600 of 66779 images scanned for faces\n",
      "3800 of 66779 images scanned for faces\n",
      "4000 of 66779 images scanned for faces\n",
      "4200 of 66779 images scanned for faces\n",
      "4400 of 66779 images scanned for faces\n",
      "4600 of 66779 images scanned for faces\n",
      "4800 of 66779 images scanned for faces\n",
      "5000 of 66779 images scanned for faces\n",
      "5200 of 66779 images scanned for faces\n",
      "5400 of 66779 images scanned for faces\n",
      "5600 of 66779 images scanned for faces\n",
      "5800 of 66779 images scanned for faces\n",
      "6000 of 66779 images scanned for faces\n",
      "6200 of 66779 images scanned for faces\n",
      "6400 of 66779 images scanned for faces\n",
      "6600 of 66779 images scanned for faces\n",
      "6800 of 66779 images scanned for faces\n",
      "7000 of 66779 images scanned for faces\n",
      "7200 of 66779 images scanned for faces\n",
      "7400 of 66779 images scanned for faces\n",
      "7600 of 66779 images scanned for faces\n",
      "7800 of 66779 images scanned for faces\n",
      "8000 of 66779 images scanned for faces\n",
      "8200 of 66779 images scanned for faces\n",
      "8400 of 66779 images scanned for faces\n",
      "8600 of 66779 images scanned for faces\n",
      "8800 of 66779 images scanned for faces\n",
      "9000 of 66779 images scanned for faces\n",
      "9200 of 66779 images scanned for faces\n",
      "9400 of 66779 images scanned for faces\n",
      "9600 of 66779 images scanned for faces\n",
      "9800 of 66779 images scanned for faces\n",
      "10000 of 66779 images scanned for faces\n",
      "10200 of 66779 images scanned for faces\n",
      "10400 of 66779 images scanned for faces\n",
      "10600 of 66779 images scanned for faces\n",
      "10800 of 66779 images scanned for faces\n",
      "11000 of 66779 images scanned for faces\n",
      "11200 of 66779 images scanned for faces\n",
      "11400 of 66779 images scanned for faces\n",
      "11600 of 66779 images scanned for faces\n",
      "11800 of 66779 images scanned for faces\n",
      "12000 of 66779 images scanned for faces\n",
      "12200 of 66779 images scanned for faces\n",
      "12400 of 66779 images scanned for faces\n",
      "12600 of 66779 images scanned for faces\n",
      "12800 of 66779 images scanned for faces\n",
      "13000 of 66779 images scanned for faces\n",
      "13200 of 66779 images scanned for faces\n",
      "13400 of 66779 images scanned for faces\n",
      "13600 of 66779 images scanned for faces\n",
      "13800 of 66779 images scanned for faces\n",
      "14000 of 66779 images scanned for faces\n",
      "14200 of 66779 images scanned for faces\n",
      "14400 of 66779 images scanned for faces\n",
      "14600 of 66779 images scanned for faces\n",
      "14800 of 66779 images scanned for faces\n",
      "15000 of 66779 images scanned for faces\n",
      "15200 of 66779 images scanned for faces\n",
      "15400 of 66779 images scanned for faces\n",
      "15600 of 66779 images scanned for faces\n",
      "15800 of 66779 images scanned for faces\n",
      "16000 of 66779 images scanned for faces\n",
      "16200 of 66779 images scanned for faces\n",
      "16400 of 66779 images scanned for faces\n",
      "16600 of 66779 images scanned for faces\n",
      "16800 of 66779 images scanned for faces\n",
      "17000 of 66779 images scanned for faces\n",
      "17200 of 66779 images scanned for faces\n",
      "17400 of 66779 images scanned for faces\n",
      "17600 of 66779 images scanned for faces\n",
      "17800 of 66779 images scanned for faces\n",
      "18000 of 66779 images scanned for faces\n",
      "18200 of 66779 images scanned for faces\n",
      "18400 of 66779 images scanned for faces\n",
      "18600 of 66779 images scanned for faces\n",
      "18800 of 66779 images scanned for faces\n",
      "19000 of 66779 images scanned for faces\n",
      "19200 of 66779 images scanned for faces\n",
      "19400 of 66779 images scanned for faces\n",
      "19600 of 66779 images scanned for faces\n",
      "19800 of 66779 images scanned for faces\n",
      "20000 of 66779 images scanned for faces\n",
      "20200 of 66779 images scanned for faces\n",
      "20400 of 66779 images scanned for faces\n",
      "20600 of 66779 images scanned for faces\n",
      "20800 of 66779 images scanned for faces\n",
      "21000 of 66779 images scanned for faces\n",
      "21200 of 66779 images scanned for faces\n",
      "21400 of 66779 images scanned for faces\n",
      "21600 of 66779 images scanned for faces\n",
      "21800 of 66779 images scanned for faces\n",
      "22000 of 66779 images scanned for faces\n",
      "22200 of 66779 images scanned for faces\n",
      "22400 of 66779 images scanned for faces\n",
      "22600 of 66779 images scanned for faces\n",
      "22800 of 66779 images scanned for faces\n",
      "23000 of 66779 images scanned for faces\n",
      "23200 of 66779 images scanned for faces\n",
      "23400 of 66779 images scanned for faces\n",
      "23600 of 66779 images scanned for faces\n",
      "23800 of 66779 images scanned for faces\n",
      "24000 of 66779 images scanned for faces\n",
      "24200 of 66779 images scanned for faces\n",
      "24400 of 66779 images scanned for faces\n",
      "24600 of 66779 images scanned for faces\n",
      "24800 of 66779 images scanned for faces\n",
      "25000 of 66779 images scanned for faces\n",
      "25200 of 66779 images scanned for faces\n",
      "25400 of 66779 images scanned for faces\n",
      "25600 of 66779 images scanned for faces\n",
      "25800 of 66779 images scanned for faces\n",
      "26000 of 66779 images scanned for faces\n",
      "26200 of 66779 images scanned for faces\n",
      "26400 of 66779 images scanned for faces\n",
      "26600 of 66779 images scanned for faces\n",
      "26800 of 66779 images scanned for faces\n",
      "27000 of 66779 images scanned for faces\n",
      "27200 of 66779 images scanned for faces\n",
      "27400 of 66779 images scanned for faces\n",
      "27600 of 66779 images scanned for faces\n",
      "27800 of 66779 images scanned for faces\n",
      "28000 of 66779 images scanned for faces\n",
      "28200 of 66779 images scanned for faces\n",
      "28400 of 66779 images scanned for faces\n",
      "28600 of 66779 images scanned for faces\n",
      "28800 of 66779 images scanned for faces\n",
      "29000 of 66779 images scanned for faces\n",
      "29200 of 66779 images scanned for faces\n",
      "29400 of 66779 images scanned for faces\n",
      "29600 of 66779 images scanned for faces\n",
      "29800 of 66779 images scanned for faces\n",
      "30000 of 66779 images scanned for faces\n",
      "30200 of 66779 images scanned for faces\n",
      "30400 of 66779 images scanned for faces\n",
      "30600 of 66779 images scanned for faces\n",
      "30800 of 66779 images scanned for faces\n",
      "31000 of 66779 images scanned for faces\n",
      "31200 of 66779 images scanned for faces\n",
      "31400 of 66779 images scanned for faces\n",
      "31600 of 66779 images scanned for faces\n",
      "31800 of 66779 images scanned for faces\n",
      "32000 of 66779 images scanned for faces\n",
      "32200 of 66779 images scanned for faces\n",
      "32400 of 66779 images scanned for faces\n",
      "32600 of 66779 images scanned for faces\n",
      "32800 of 66779 images scanned for faces\n",
      "33000 of 66779 images scanned for faces\n",
      "33200 of 66779 images scanned for faces\n",
      "33400 of 66779 images scanned for faces\n",
      "33600 of 66779 images scanned for faces\n",
      "33800 of 66779 images scanned for faces\n",
      "34000 of 66779 images scanned for faces\n",
      "34200 of 66779 images scanned for faces\n",
      "34400 of 66779 images scanned for faces\n",
      "34600 of 66779 images scanned for faces\n",
      "34800 of 66779 images scanned for faces\n",
      "35000 of 66779 images scanned for faces\n",
      "35200 of 66779 images scanned for faces\n",
      "35400 of 66779 images scanned for faces\n",
      "35600 of 66779 images scanned for faces\n",
      "35800 of 66779 images scanned for faces\n",
      "36000 of 66779 images scanned for faces\n",
      "36200 of 66779 images scanned for faces\n",
      "36400 of 66779 images scanned for faces\n",
      "36600 of 66779 images scanned for faces\n",
      "36800 of 66779 images scanned for faces\n",
      "37000 of 66779 images scanned for faces\n",
      "37200 of 66779 images scanned for faces\n",
      "37400 of 66779 images scanned for faces\n",
      "37600 of 66779 images scanned for faces\n",
      "37800 of 66779 images scanned for faces\n",
      "38000 of 66779 images scanned for faces\n",
      "38200 of 66779 images scanned for faces\n",
      "38400 of 66779 images scanned for faces\n",
      "38600 of 66779 images scanned for faces\n",
      "38800 of 66779 images scanned for faces\n",
      "39000 of 66779 images scanned for faces\n",
      "39200 of 66779 images scanned for faces\n",
      "39400 of 66779 images scanned for faces\n",
      "39600 of 66779 images scanned for faces\n",
      "39800 of 66779 images scanned for faces\n",
      "40000 of 66779 images scanned for faces\n",
      "40200 of 66779 images scanned for faces\n",
      "40400 of 66779 images scanned for faces\n",
      "40600 of 66779 images scanned for faces\n",
      "40800 of 66779 images scanned for faces\n",
      "41000 of 66779 images scanned for faces\n",
      "41200 of 66779 images scanned for faces\n",
      "41400 of 66779 images scanned for faces\n",
      "41600 of 66779 images scanned for faces\n",
      "41800 of 66779 images scanned for faces\n",
      "42000 of 66779 images scanned for faces\n",
      "42200 of 66779 images scanned for faces\n",
      "42400 of 66779 images scanned for faces\n",
      "42600 of 66779 images scanned for faces\n",
      "42800 of 66779 images scanned for faces\n",
      "43000 of 66779 images scanned for faces\n",
      "43200 of 66779 images scanned for faces\n",
      "43400 of 66779 images scanned for faces\n",
      "43600 of 66779 images scanned for faces\n",
      "43800 of 66779 images scanned for faces\n",
      "44000 of 66779 images scanned for faces\n",
      "44200 of 66779 images scanned for faces\n",
      "44400 of 66779 images scanned for faces\n",
      "44600 of 66779 images scanned for faces\n",
      "44800 of 66779 images scanned for faces\n",
      "45000 of 66779 images scanned for faces\n",
      "45200 of 66779 images scanned for faces\n",
      "45400 of 66779 images scanned for faces\n",
      "45600 of 66779 images scanned for faces\n",
      "45800 of 66779 images scanned for faces\n",
      "46000 of 66779 images scanned for faces\n",
      "46200 of 66779 images scanned for faces\n",
      "46400 of 66779 images scanned for faces\n",
      "46600 of 66779 images scanned for faces\n",
      "46800 of 66779 images scanned for faces\n",
      "47000 of 66779 images scanned for faces\n",
      "47200 of 66779 images scanned for faces\n",
      "47400 of 66779 images scanned for faces\n",
      "47600 of 66779 images scanned for faces\n",
      "47800 of 66779 images scanned for faces\n",
      "48000 of 66779 images scanned for faces\n",
      "48200 of 66779 images scanned for faces\n",
      "48400 of 66779 images scanned for faces\n",
      "48600 of 66779 images scanned for faces\n",
      "48800 of 66779 images scanned for faces\n",
      "49000 of 66779 images scanned for faces\n",
      "49200 of 66779 images scanned for faces\n",
      "49400 of 66779 images scanned for faces\n",
      "49600 of 66779 images scanned for faces\n",
      "49800 of 66779 images scanned for faces\n",
      "50000 of 66779 images scanned for faces\n",
      "50200 of 66779 images scanned for faces\n",
      "50400 of 66779 images scanned for faces\n",
      "50600 of 66779 images scanned for faces\n",
      "50800 of 66779 images scanned for faces\n",
      "51000 of 66779 images scanned for faces\n",
      "51200 of 66779 images scanned for faces\n",
      "51400 of 66779 images scanned for faces\n",
      "51600 of 66779 images scanned for faces\n",
      "51800 of 66779 images scanned for faces\n",
      "52000 of 66779 images scanned for faces\n",
      "52200 of 66779 images scanned for faces\n",
      "52400 of 66779 images scanned for faces\n",
      "52600 of 66779 images scanned for faces\n",
      "52800 of 66779 images scanned for faces\n",
      "53000 of 66779 images scanned for faces\n",
      "53200 of 66779 images scanned for faces\n",
      "53400 of 66779 images scanned for faces\n",
      "53600 of 66779 images scanned for faces\n",
      "53800 of 66779 images scanned for faces\n",
      "54000 of 66779 images scanned for faces\n",
      "54200 of 66779 images scanned for faces\n",
      "54400 of 66779 images scanned for faces\n",
      "54600 of 66779 images scanned for faces\n",
      "54800 of 66779 images scanned for faces\n",
      "55000 of 66779 images scanned for faces\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "[17:10:51] src/storage/./pooled_storage_manager.h:161: cudaMalloc retry failed: out of memory\nStack trace:\n  [bt] (0) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x6b8b5b) [0x7f24c5242b5b]\n  [bt] (1) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x40bf542) [0x7f24c8c49542]\n  [bt] (2) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x40c521f) [0x7f24c8c4f21f]\n  [bt] (3) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4651af3) [0x7f24c91dbaf3]\n  [bt] (4) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x463ee84) [0x7f24c91c8e84]\n  [bt] (5) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x463f407) [0x7f24c91c9407]\n  [bt] (6) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x46407f2) [0x7f24c91ca7f2]\n  [bt] (7) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4641973) [0x7f24c91cb973]\n  [bt] (8) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4647911) [0x7f24c91d1911]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cd88289576ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtemplates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_templates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8992498063b3>\u001b[0m in \u001b[0;36mbuild_templates\u001b[0;34m(num, show_images)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/focus/pfe/retinaface.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, threshold, scales, do_flip)\u001b[0m\n\u001b[1;32m    246\u001b[0m               \u001b[0;31m#  continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m               \u001b[0;31m#print('getting', im_scale, stride, idx, len(net_out), data.shape, file=sys.stderr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m               \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msym_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mtimeb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fenv/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fenv/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \"\"\"\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [17:10:51] src/storage/./pooled_storage_manager.h:161: cudaMalloc retry failed: out of memory\nStack trace:\n  [bt] (0) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x6b8b5b) [0x7f24c5242b5b]\n  [bt] (1) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x40bf542) [0x7f24c8c49542]\n  [bt] (2) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x40c521f) [0x7f24c8c4f21f]\n  [bt] (3) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4651af3) [0x7f24c91dbaf3]\n  [bt] (4) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x463ee84) [0x7f24c91c8e84]\n  [bt] (5) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x463f407) [0x7f24c91c9407]\n  [bt] (6) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x46407f2) [0x7f24c91ca7f2]\n  [bt] (7) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4641973) [0x7f24c91cb973]\n  [bt] (8) /home/spopov/fenv/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4647911) [0x7f24c91d1911]\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluation.eval_ijb_8 as eval_ijb\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "templates = build_templates()\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "proc_func = lambda templates: preprocess(np.array([template.img for template in templates]), network.config)\n",
    "mu, sigma_sq = network.extract_feature(templates, BATCH_SIZE, proc_func=proc_func, verbose=True)\n",
    "confidences = np.array([confidence_sigma(sigma_sq_i) for sigma_sq_i in sigma_sq])\n",
    "confidences = confidences / np.max(confidences)\n",
    "features = np.concatenate([mu, sigma_sq], axis=1)\n",
    "\n",
    "np.savetxt(\"features.csv\", features, delimiter=\",\")\n",
    "templates_BACKUP = templates\n",
    "features_BACKUP = features\n",
    "\n",
    "MAX_SIMILARITY = max_similarity(features)\n",
    "\n",
    "print(features.shape)\n",
    "print(features)\n",
    "\n",
    "clt = DBSCAN(metric=distance_func, n_jobs=-1, min_samples=2, eps=0.18)\n",
    "\n",
    "clt.fit(features)\n",
    "\n",
    "print(clt.labels_)\n",
    "labels = clt.labels_\n",
    "\n",
    "COLUMN_NAMES=['TEMPLATE_ID','FILENAME','CLUSTER_INDEX','CONFIDENCE','FACE_X','FACE_Y','FACE_WIDTH','FACE_HEIGHT']\n",
    "\n",
    "row_list = []\n",
    "for i, template in enumerate(templates):\n",
    "    row_list.append({'TEMPLATE_ID': i,\n",
    "              'FILENAME': template.filename,\n",
    "              'CLUSTER_INDEX': labels[i],\n",
    "              'CONFIDENCE': confidences[i],\n",
    "              'FACE_X': template.box[0],\n",
    "              'FACE_Y': template.box[1],\n",
    "              'FACE_WIDTH': template.box[2],\n",
    "              'FACE_HEIGHT': template.box[3]})\n",
    "\n",
    "df = pd.DataFrame(row_list, columns=COLUMN_NAMES)\n",
    "\n",
    "df.to_csv(CLUSTERS_FILEPATH, index=False)\n",
    "print(df)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Calculating presicion, recall and F-measure...')\n",
    "result = subprocess.run(['python', EVAL_SCRIPT_PATH, CLUSTERS_FILEPATH, GROUND_TRUTH_FILEPATH], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(result.stdout.decode('utf-8'))\n",
    "print(result.stderr.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))\n",
    "L = len(features)\n",
    "\n",
    "dists = [[distance_func(features[i], features[j]) for j in range(L)] for i in range (L)]\n",
    "dists = np.array(dists)\n",
    "print(dists)\n",
    "\n",
    "for i, t in enumerate(templates):\n",
    "\n",
    "    print(i)\n",
    "    t.draw()\n",
    "    print(dists[i])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
